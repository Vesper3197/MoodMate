{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f93dfee7-98a8-4e93-bbe7-0e62bbaf36a0",
   "metadata": {},
   "source": [
    "# MoodMate: A Sentiment-Responsive Question-Answering Psychologist Chatbot for Emotional Support By Fine-tuning Llama-3.2-3B-Instruct Model\n",
    "\n",
    "Developed by **Group 9**:\n",
    "\n",
    "* Jiesen LONG, 2230026109\n",
    "* Zhiyue CHOU, 2230026028\n",
    "* Jiaying SHAN, 2230026230\n",
    "* Yizhen XIN, 2230026179\n",
    "* Ruoyi WANG, 2230026155\n",
    "* Shuxuan DING, 2230026232\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882594ca-5b55-4e5c-aeef-0c8a5a2091e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import gc\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import accelerate\n",
    "import bitsandbytes as bnb\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060a0f60-3fd0-46be-947f-77a918776cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"dataset/combined_data.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91fb2acb-3272-4a35-917b-d4065e3c69e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output'],\n",
       "    num_rows: 50328\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f408cfd8-841b-41a0-9b11-df14ce0b384d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'心理咨询师，我觉得我很自私，因为我总是关心自己的感受，有时候会忽略别人的感受。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['input'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a74c77-6f48-428f-9e76-ea69715d2b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你能详细描述一下这种情况吗？例如在什么情况下你会觉得自己自私？'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['output'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4081c353-2e42-41bd-ab2b-342ef06d29dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My daughter is in later elementary school. She can't color in the lines. Her words jumble together when she writes unless there are big spaces or she skips lines.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['input'][50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "997a6cb4-edc6-4e7f-aea8-cdfe83b14e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There could be a number of things going on here. For instance, have her eyes been checked by an optometrist? She might just not like writing or coloring. She could be rushing through assignments so that she can spend time with friends, play games, or do something else. She might need some extra help with fine motor skills. What are her grades like? Does she rush through other things like cleaning her room or getting ready for bed? '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['output'][50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13c85e59-a087-423a-8ff7-32190edc02ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787b49d1730f4ba3b92a47da8bc71732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "#Load Tokenizer\n",
    "tokenizer= AutoTokenizer.from_pretrained('model_3b')\n",
    "\n",
    "# Add Padding Token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# Load the LLaMA model in 4-bit\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    \"model_3b\",\n",
    "    quantization_config=nf4_config,\n",
    "    low_cpu_mem_usage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb8ee4d2-94bf-45f0-898e-fcb63003e449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LoRA config based on QLoRA paper\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        r=64,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e5a61e2-f4ad-40aa-951e-b55c96a4a38b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare model for training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b01aca7e-e997-4d3a-ba2d-d1c9a303caac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"CounselLlama1B\",\n",
    "    logging_dir='./results',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_checkpointing=False,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    load_best_model_at_end=True,\n",
    "    eval_strategy='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "803bf225-b058-4cce-a6ee-52dd3b438899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# System message to better instruct chatbot\n",
    "system_message = \"\"\"You are a helpful and and truthful psychology and psychotherapy assistant. Your primary role is to provide empathetic, understanding, and non-judgmental responses to users seeking emotional and psychological support.\n",
    "                  Always respond with empathy and demonstrate active listening; try to focus on the user. Your responses should reflect that you understand the user's feelings and concerns. If a user expresses thoughts of self-harm, suicide, or harm to others, prioritize their safety.\n",
    "                  Encourage them to seek immediate professional help and provide emergency contact numbers when appropriate.  You are not a licensed medical professional. Do not diagnose or prescribe treatments.\n",
    "                  Instead, encourage users to consult with a licensed therapist or medical professional for specific advice. Avoid taking sides or expressing personal opinions. Your role is to provide a safe space for users to share and reflect.\n",
    "                  Remember, your goal is to provide a supportive and understanding environment for users to share their feelings and concerns. Always prioritize their well-being and safety.\"\"\"\n",
    "\n",
    "def format_llama(entry):\n",
    "    formatted = f\"<s>[INST] <<SYS>>{system_message}<</SYS>>{entry['input']} [/INST]  {entry['output']}  </s>\"\n",
    "\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56540f9d-5d97-4790-96fd-7676e4458ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset in 8:2\n",
    "dataset_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "train_dataset = dataset_split['train']\n",
    "valid_dataset = dataset_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c9402a1-08a3-43f7-b36d-a94a60f509a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>You are a helpful and and truthful psychology and psychotherapy assistant. Your primary role is to provide empathetic, understanding, and non-judgmental responses to users seeking emotional and psychological support.\n",
      "                  Always respond with empathy and demonstrate active listening; try to focus on the user. Your responses should reflect that you understand the user's feelings and concerns. If a user expresses thoughts of self-harm, suicide, or harm to others, prioritize their safety.\n",
      "                  Encourage them to seek immediate professional help and provide emergency contact numbers when appropriate.  You are not a licensed medical professional. Do not diagnose or prescribe treatments.\n",
      "                  Instead, encourage users to consult with a licensed therapist or medical professional for specific advice. Avoid taking sides or expressing personal opinions. Your role is to provide a safe space for users to share and reflect.\n",
      "                  Remember, your goal is to provide a supportive and understanding environment for users to share their feelings and concerns. Always prioritize their well-being and safety.<</SYS>>好的，我会试着去表达自己。谢谢你的鼓励和支持。 [/INST]  不客气。让我们一起努力，相信你一定能度过这段困难时期。每星期我们都会见面，让你的生活逐渐走向正轨。请相信，阳光总会照进心里。  </s>\n"
     ]
    }
   ],
   "source": [
    "print(format_llama(train_dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bba64bb3-3dbe-4d4e-960f-b6a1daa68f19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, packing. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/root/miniconda3/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:195: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:401: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "Detected kernel version 4.19.90, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048 # max sequence length for model and packing of the dataset\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True,\n",
    "    formatting_func=format_llama,\n",
    "    args=args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db42adb8-6e8f-49d5-a54f-fb7f8e00d505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e762ad0e-daf1-4c07-87c1-8b5735e09f61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14900' max='14900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14900/14900 11:36:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>0.460894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>0.440682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.428281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.514800</td>\n",
       "      <td>0.419215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.408500</td>\n",
       "      <td>0.412057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.904500</td>\n",
       "      <td>0.404542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.399189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.394552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.390680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.336400</td>\n",
       "      <td>0.387674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14900, training_loss=0.4174032885916281, metrics={'train_runtime': 41788.6875, 'train_samples_per_second': 1.426, 'train_steps_per_second': 0.357, 'total_flos': 2.0767444550497075e+18, 'train_loss': 0.4174032885916281, 'epoch': 10.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.args.gradient_checkpointing = False\n",
    "\n",
    "# train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1335c11-ae00-4a3d-b590-ca1e243be6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "trainer.save_model(\"./fine_tuned_model_3b\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
